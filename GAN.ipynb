{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNgKAgTTZPG/EWb0AJcZcL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aeyjeyaryan/Deep-Learning/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gy4tCCLKdrrs"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow numpy matplotlib --q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import os\n",
        "\n",
        "os.makedirs('mnist_samples', exist_ok=True)\n",
        "\n",
        "# Disable eager execution if you want to continue using TF1.x style code\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Or better, use TF2 with Keras - which is what we'll do here\n",
        "\n",
        "def load_data():\n",
        "    (x_train, _), (_, _) = mnist.load_data()\n",
        "    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "    # Reshaping\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "    return x_train\n",
        "\n",
        "# Hyperparameters for the base nets\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.0002\n",
        "BETA_1 = 0.5  # Adam optimizer will use this as paramaeter\n",
        "\n",
        "NOISE_DIM = 100  # Noise dimension\n",
        "IMAGE_SIZE = 28\n",
        "IMAGE_CHANNELS = 1\n",
        "\n",
        "#The generator\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # First fully connected layer, reshaped to 7x7x128\n",
        "    model.add(tf.keras.layers.Dense(7*7*128, use_bias=False, input_shape=(NOISE_DIM,)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Reshape((7, 7, 128)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# The Discriminator\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # First conv layer\n",
        "    model.add(tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # second conv\n",
        "    model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "# loss function\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Discriminator's loss\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "# Generator's loss\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Optimizers\n",
        "generator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE, beta_1=BETA_1)\n",
        "\n",
        "# Creating the generator and discrimninator\n",
        "# note to self: Will use the same function in other experimentation\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "# Generate noise samples\n",
        "def generate_noise(num_samples):\n",
        "    return tf.random.normal([num_samples, NOISE_DIM])\n",
        "\n",
        "# Save generated images\n",
        "def save_images(epoch, generator, examples=10):\n",
        "    noise = generate_noise(examples)\n",
        "    generated_images = generator(noise, training=False)\n",
        "\n",
        "    generated_images = (generated_images * 0.5) + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(1, examples, figsize=(examples * 2, 2))\n",
        "    for i in range(examples):\n",
        "        if examples > 1:\n",
        "            axs[i].imshow(generated_images[i, :, :, 0], cmap='gray')\n",
        "            axs[i].axis('off')\n",
        "        else:\n",
        "            axs.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
        "            axs.axis('off')\n",
        "    plt.savefig(f'mnist_samples/epoch_{epoch:03d}.png', bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "# Define the training step\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = generate_noise(BATCH_SIZE)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate fake images\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        # Get discriminator outputs for real and fake images\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        # Calculate losses\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "# take number input\n",
        "def generate_user_images(generator, num_images):\n",
        "    noise = generate_noise(num_images)\n",
        "    generated_images = generator(noise, training=False)\n",
        "    generated_images = (generated_images * 0.5) + 0.5  # Rescale to [0, 1]\n",
        "\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(num_images * 2, 2))\n",
        "    if num_images == 1:\n",
        "        axs.imshow(generated_images[0, :, :, 0], cmap='gray')\n",
        "        axs.axis('off')\n",
        "    else:\n",
        "        for i in range(num_images):\n",
        "            axs[i].imshow(generated_images[i, :, :, 0], cmap='gray')\n",
        "            axs[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        epoch_gen_loss = 0\n",
        "        epoch_disc_loss = 0\n",
        "        batches = 0\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(image_batch)\n",
        "            epoch_gen_loss += gen_loss\n",
        "            epoch_disc_loss += disc_loss\n",
        "            batches += 1\n",
        "\n",
        "        epoch_gen_loss /= batches\n",
        "        epoch_disc_loss /= batches\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, D Loss: {epoch_disc_loss:.4f}, G Loss: {epoch_gen_loss:.4f}')\n",
        "\n",
        "        # Save sample images every 10 epochs\n",
        "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "            save_images(epoch, generator)\n",
        "\n",
        "    print('Training Finished!')\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    train_images = load_data()\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(BATCH_SIZE)\n",
        "\n",
        "    train(train_dataset, EPOCHS) #gan trains here\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            num_images = int(input(\"\\nEnter the number of images to generate (1-10, or 0 to exit): \"))\n",
        "            if num_images == 0:\n",
        "                break\n",
        "            if 1 <= num_images <= 10:\n",
        "                generate_user_images(generator, num_images)\n",
        "            else:\n",
        "                print(\"Please enter a number between 1 and 10\")\n",
        "        except ValueError:\n",
        "            print(\"Please enter a valid number\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KZog3XXGeuFW",
        "outputId": "b9874781-b8b5-462b-d66d-294b0806a371"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, D Loss: 0.5518, G Loss: 1.8200\n",
            "Epoch 2/100, D Loss: 0.7432, G Loss: 1.5257\n",
            "Epoch 3/100, D Loss: 0.7199, G Loss: 1.5958\n",
            "Epoch 4/100, D Loss: 0.7055, G Loss: 1.6734\n",
            "Epoch 5/100, D Loss: 0.7090, G Loss: 1.7246\n",
            "Epoch 6/100, D Loss: 0.6901, G Loss: 1.7688\n",
            "Epoch 7/100, D Loss: 0.6942, G Loss: 1.8311\n",
            "Epoch 8/100, D Loss: 0.6570, G Loss: 1.8707\n",
            "Epoch 9/100, D Loss: 0.6441, G Loss: 1.9314\n",
            "Epoch 10/100, D Loss: 0.6519, G Loss: 1.9768\n",
            "Epoch 11/100, D Loss: 0.6542, G Loss: 2.0064\n",
            "Epoch 12/100, D Loss: 0.5945, G Loss: 2.0524\n",
            "Epoch 13/100, D Loss: 0.6659, G Loss: 2.0729\n",
            "Epoch 14/100, D Loss: 0.6233, G Loss: 2.1011\n",
            "Epoch 15/100, D Loss: 0.6137, G Loss: 2.1284\n",
            "Epoch 16/100, D Loss: 0.6180, G Loss: 2.1406\n",
            "Epoch 17/100, D Loss: 0.6038, G Loss: 2.1625\n",
            "Epoch 18/100, D Loss: 0.5882, G Loss: 2.2095\n",
            "Epoch 19/100, D Loss: 0.5564, G Loss: 2.2370\n",
            "Epoch 20/100, D Loss: 0.5679, G Loss: 2.2754\n",
            "Epoch 21/100, D Loss: 0.5929, G Loss: 2.2660\n",
            "Epoch 22/100, D Loss: 0.5789, G Loss: 2.2889\n",
            "Epoch 23/100, D Loss: 0.5505, G Loss: 2.3433\n",
            "Epoch 24/100, D Loss: 0.5985, G Loss: 2.3191\n",
            "Epoch 25/100, D Loss: 0.5270, G Loss: 2.3639\n",
            "Epoch 26/100, D Loss: 0.5553, G Loss: 2.3667\n",
            "Epoch 27/100, D Loss: 0.5640, G Loss: 2.3647\n",
            "Epoch 28/100, D Loss: 0.5316, G Loss: 2.4106\n",
            "Epoch 29/100, D Loss: 0.5605, G Loss: 2.4200\n",
            "Epoch 30/100, D Loss: 0.5430, G Loss: 2.4448\n",
            "Epoch 31/100, D Loss: 0.5792, G Loss: 2.4183\n",
            "Epoch 32/100, D Loss: 0.5191, G Loss: 2.4306\n",
            "Epoch 33/100, D Loss: 0.5397, G Loss: 2.4537\n",
            "Epoch 34/100, D Loss: 0.5134, G Loss: 2.4879\n",
            "Epoch 35/100, D Loss: 0.5455, G Loss: 2.4914\n",
            "Epoch 36/100, D Loss: 0.5038, G Loss: 2.5261\n",
            "Epoch 37/100, D Loss: 0.5462, G Loss: 2.5228\n",
            "Epoch 38/100, D Loss: 0.4982, G Loss: 2.5594\n",
            "Epoch 39/100, D Loss: 0.5342, G Loss: 2.5406\n",
            "Epoch 40/100, D Loss: 0.4964, G Loss: 2.5853\n",
            "Epoch 41/100, D Loss: 0.5023, G Loss: 2.5891\n",
            "Epoch 42/100, D Loss: 0.4963, G Loss: 2.6153\n",
            "Epoch 43/100, D Loss: 0.5141, G Loss: 2.6332\n",
            "Epoch 44/100, D Loss: 0.5113, G Loss: 2.6136\n",
            "Epoch 45/100, D Loss: 0.4791, G Loss: 2.6655\n",
            "Epoch 46/100, D Loss: 0.5525, G Loss: 2.6489\n",
            "Epoch 47/100, D Loss: 0.4786, G Loss: 2.6134\n",
            "Epoch 48/100, D Loss: 0.4760, G Loss: 2.6974\n",
            "Epoch 49/100, D Loss: 0.5001, G Loss: 2.7042\n",
            "Epoch 50/100, D Loss: 0.4690, G Loss: 2.7186\n",
            "Epoch 51/100, D Loss: 0.4605, G Loss: 2.7553\n",
            "Epoch 52/100, D Loss: 0.5061, G Loss: 2.7441\n",
            "Epoch 53/100, D Loss: 0.4434, G Loss: 2.7740\n",
            "Epoch 54/100, D Loss: 0.4683, G Loss: 2.8040\n",
            "Epoch 55/100, D Loss: 0.4474, G Loss: 2.8356\n",
            "Epoch 56/100, D Loss: 0.5181, G Loss: 2.8166\n",
            "Epoch 57/100, D Loss: 0.4301, G Loss: 2.8114\n",
            "Epoch 58/100, D Loss: 0.4645, G Loss: 2.8449\n",
            "Epoch 59/100, D Loss: 0.4475, G Loss: 2.8852\n",
            "Epoch 60/100, D Loss: 0.5012, G Loss: 2.8644\n",
            "Epoch 61/100, D Loss: 0.4256, G Loss: 2.8846\n",
            "Epoch 62/100, D Loss: 0.4509, G Loss: 2.9240\n",
            "Epoch 63/100, D Loss: 0.4202, G Loss: 2.9619\n",
            "Epoch 64/100, D Loss: 0.4809, G Loss: 2.9343\n",
            "Epoch 65/100, D Loss: 0.4166, G Loss: 2.9758\n",
            "Epoch 66/100, D Loss: 0.4212, G Loss: 3.0117\n",
            "Epoch 67/100, D Loss: 0.4586, G Loss: 2.9725\n",
            "Epoch 68/100, D Loss: 0.4370, G Loss: 3.0162\n",
            "Epoch 69/100, D Loss: 0.4042, G Loss: 3.0488\n",
            "Epoch 70/100, D Loss: 0.4257, G Loss: 3.0586\n",
            "Epoch 71/100, D Loss: 0.4028, G Loss: 3.0827\n",
            "Epoch 72/100, D Loss: 0.4672, G Loss: 3.0251\n",
            "Epoch 73/100, D Loss: 0.3864, G Loss: 3.1132\n",
            "Epoch 74/100, D Loss: 0.4285, G Loss: 3.0971\n",
            "Epoch 75/100, D Loss: 0.4216, G Loss: 3.0983\n",
            "Epoch 76/100, D Loss: 0.3987, G Loss: 3.1389\n",
            "Epoch 77/100, D Loss: 0.4448, G Loss: 3.1129\n",
            "Epoch 78/100, D Loss: 0.3698, G Loss: 3.1710\n",
            "Epoch 79/100, D Loss: 0.4555, G Loss: 3.1467\n",
            "Epoch 80/100, D Loss: 0.3645, G Loss: 3.2144\n",
            "Epoch 81/100, D Loss: 0.4406, G Loss: 3.1809\n",
            "Epoch 82/100, D Loss: 0.3745, G Loss: 3.2096\n",
            "Epoch 83/100, D Loss: 0.3841, G Loss: 3.2389\n",
            "Epoch 84/100, D Loss: 0.4203, G Loss: 3.2029\n",
            "Epoch 85/100, D Loss: 0.3641, G Loss: 3.2594\n",
            "Epoch 86/100, D Loss: 0.3954, G Loss: 3.2472\n",
            "Epoch 87/100, D Loss: 0.3774, G Loss: 3.2847\n",
            "Epoch 88/100, D Loss: 0.4321, G Loss: 3.2312\n",
            "Epoch 89/100, D Loss: 0.4071, G Loss: 3.3170\n",
            "Epoch 90/100, D Loss: 0.3602, G Loss: 3.2815\n",
            "Epoch 91/100, D Loss: 0.3605, G Loss: 3.3500\n",
            "Epoch 92/100, D Loss: 0.3657, G Loss: 3.3731\n",
            "Epoch 93/100, D Loss: 0.4309, G Loss: 3.3157\n",
            "Epoch 94/100, D Loss: 0.3351, G Loss: 3.3842\n",
            "Epoch 95/100, D Loss: 0.3858, G Loss: 3.3648\n",
            "Epoch 96/100, D Loss: 0.3609, G Loss: 3.4000\n",
            "Epoch 97/100, D Loss: 0.3805, G Loss: 3.3935\n",
            "Epoch 98/100, D Loss: 0.3514, G Loss: 3.4085\n",
            "Epoch 99/100, D Loss: 0.3799, G Loss: 3.4004\n",
            "Epoch 100/100, D Loss: 0.3759, G Loss: 3.4088\n",
            "Training Finished!\n",
            "\n",
            "Enter the number of images to generate (1-10, or 0 to exit): 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fqpFyrZKrZT1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}